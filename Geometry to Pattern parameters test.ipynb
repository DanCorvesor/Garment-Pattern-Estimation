{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import scipy.io  # for reading matlab matrix\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import openmesh as om"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility when testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ba4373ad70>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# when using cuda\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\D\n",
      "\n",
      "<>:1: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\D\n",
      "\n",
      "<>:1: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\D\n",
      "\n",
      "<ipython-input-54-4448b5311408>:1: DeprecationWarning:\n",
      "\n",
      "invalid escape sequence \\D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_location = 'D:\\Data\\CLOTHING\\Learning Shared Shape Space_shirt_dataset_rest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom DataSet class\n",
    "class ParametrizedShirtDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    For loading the data of \"Learning Shared Shape Space..\" paper\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the t-shirt examples as subfolders\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.root_path = Path(root_dir)\n",
    "        \n",
    "        # list of items = subfolders\n",
    "        self.datapoints_names = next(os.walk(self.root_path))[1]\n",
    "        \n",
    "        # remove non-valid element\n",
    "        self.datapoints_names.remove('P3ORMPBNJJAJ')\n",
    "        \n",
    "        \n",
    "        # datapoint folder structure\n",
    "        self.mesh_filename = 'shirt_mesh_r.obj'\n",
    "        self.pattern_params_filename = 'shirt_info.txt'\n",
    "        self.features_filename = 'visfea.mat'\n",
    "        self.garment_3d_filename = 'shirt_mesh_r_tmp.obj'\n",
    "        \n",
    "    def update_transform(self, transform):\n",
    "        \"\"\"apply new transform when loading the data\"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of entries in the dataset\"\"\"\n",
    "        return len(self.datapoints_names)\n",
    "    \n",
    "    \n",
    "    def read_verts(self, datapoint_name):\n",
    "        \"\"\"features parameters from a given datapoint subfolder\"\"\"\n",
    "        assert (self.root_path / datapoint_name / self.garment_3d_filename).exists(), datapoint_name\n",
    "        \n",
    "        mesh = om.read_trimesh(str(self.root_path / datapoint_name / self.garment_3d_filename))\n",
    "        \n",
    "        return mesh.points()\n",
    "    \n",
    "    \n",
    "    def read_pattern_params(self, datapoint_name):\n",
    "        \"\"\"9 pattern size parameters from a given datapoint subfolder\"\"\"\n",
    "        assert (self.root_path / datapoint_name / self.pattern_params_filename).exists(), datapoint_name\n",
    "        \n",
    "        # assuming that we need the numbers from the last line in file\n",
    "        with open(self.root_path / datapoint_name / self.pattern_params_filename) as f:\n",
    "            lines = f.readlines()\n",
    "            params = np.fromstring(lines[-1],  sep = ' ')\n",
    "        return params\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Called when indexing: read the corresponding data. \n",
    "        Does not support list indexing\"\"\"\n",
    "        \n",
    "        if torch.is_tensor(idx):  # allow indexing by tensors\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        datapoint_name = self.datapoints_names[idx]\n",
    "        \n",
    "        vert_list = self.read_verts(datapoint_name)\n",
    "        \n",
    "        # read the pattern parameters\n",
    "        pattern_parameters = self.read_pattern_params(datapoint_name)\n",
    "        \n",
    "        sample = {'features': vert_list.ravel(), 'pattern_params': pattern_parameters, 'name': datapoint_name}\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "        \n",
    "        \n",
    "    def save_prediction_batch(self, predicted_params, names):\n",
    "        \"\"\"Saves predicted params of the datapoint to the original data folder\"\"\"\n",
    "        \n",
    "        for prediction, name in zip(predicted_params, names):\n",
    "            path_to_prediction = self.root_path / '..' / 'predictions' / name\n",
    "            try:\n",
    "                os.makedirs(path_to_prediction)\n",
    "            except OSError:\n",
    "                pass\n",
    "            \n",
    "            prediction = prediction.tolist()\n",
    "            with open(path_to_prediction / self.pattern_params_filename, 'w+') as f:\n",
    "                f.writelines(['0\\n', '0\\n', ' '.join(map(str, prediction))])\n",
    "                print ('Saved ' + name)\n",
    "    \n",
    "    def feature_size(self):\n",
    "        return 12252 * 3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transforms -- to tensor\n",
    "class SampleToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        features, params = sample['features'], sample['pattern_params']\n",
    "        \n",
    "        return {\n",
    "                'features': torch.from_numpy(features).float(), \n",
    "                'pattern_params': torch.from_numpy(params).float(), \n",
    "                'name': sample['name']\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transforms -- normalize\n",
    "class NormalizeInputfeatures(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __init__(self, mean_features, std_features):\n",
    "        self.mean = mean_features\n",
    "        self.std = std_features\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        features = sample['features']\n",
    "        \n",
    "        return {\n",
    "                    'features': torch.div((features - self.mean), self.std), \n",
    "                    'pattern_params': sample['pattern_params'], \n",
    "                    'name': sample['name']\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normalization?\n",
    "\n",
    "def get_mean_std(dataloader):\n",
    "    \n",
    "    stats = { 'batch_sums' : [], 'batch_sq_sums' : []}\n",
    "    \n",
    "    for data in dataloader:\n",
    "        batch_sum = data['features'].sum(0)\n",
    "        stats['batch_sums'].append(batch_sum)\n",
    "\n",
    "    mean_features = sum(stats['batch_sums']) / len(dataloader)\n",
    "    \n",
    "    for data in dataloader:\n",
    "        batch_sum_sq = (data['features'] - mean_features.view(1, len(mean_features)))**2\n",
    "        stats['batch_sq_sums'].append(batch_sum_sq.sum(0))\n",
    "                        \n",
    "    std_features = torch.sqrt(sum(stats['batch_sq_sums']) / len(dataloader))\n",
    "    \n",
    "    return mean_features, std_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1049\n",
      "tensor([-2.6803, 12.6441, -0.1044,  ...,  2.7306, 12.6700, -0.0931])\n",
      "torch.Size([36756])\n",
      "torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# test loading\n",
    "dataset = ParametrizedShirtDataSet(Path(data_location), \n",
    "                                  SampleToTensor())\n",
    "\n",
    "print (len(dataset))\n",
    "print (dataset[100]['features'])\n",
    "print (dataset[100]['features'].shape)\n",
    "print (dataset[0]['pattern_params'].shape)\n",
    "#print (dataset[1000])\n",
    "\n",
    "#loader = DataLoader(dataset, 10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if all elements are avaliable\n",
    "\n",
    "\n",
    "for name in dataset.datapoints_names:\n",
    "    if not (dataset.root_path / name / dataset.garment_3d_filename).exists():\n",
    "        print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4847, 1.7808, 2.5189, 2.8437, 4.7678, 6.1286, 6.0374, 6.0461, 6.0504,\n",
      "        6.0500, 6.0500, 6.0500, 6.0501, 6.0495, 6.0338, 6.0290, 6.0191, 6.0103,\n",
      "        6.0033, 5.9944, 5.9856, 5.9771, 5.9658, 5.9569, 5.9481, 5.9396, 5.9291,\n",
      "        5.9197, 5.9068, 5.9005, 5.7688, 5.1725, 4.5954, 3.9547, 2.9973, 2.3022,\n",
      "        2.2025, 2.1716, 2.1283, 2.0894, 2.0596, 2.0363, 2.0191, 2.0048, 1.9907,\n",
      "        1.9804, 1.9743, 1.9572, 1.9458, 1.9341, 1.9225, 1.9199, 1.9182, 1.9112,\n",
      "        1.9119, 1.9027, 1.9047, 1.8997, 1.9000, 1.9002, 1.8983, 1.8905, 1.8855,\n",
      "        1.8806, 1.8821, 1.8798, 1.8794, 1.8862, 1.9059, 1.9212, 1.9365, 1.9526,\n",
      "        1.9691, 1.9886, 2.0051, 2.0236, 2.0428, 2.0614, 2.0781, 2.0829, 2.1120,\n",
      "        2.1466, 2.1775, 2.2130, 2.2419, 2.2715, 2.3000, 2.3252, 2.3484, 2.3717,\n",
      "        2.3947, 2.4142, 2.4290, 2.4452, 2.4613, 2.4773, 2.5043, 2.3297, 1.7479,\n",
      "        0.7207])\n",
      "tensor([-0.3243, -0.3104, -0.3113, -0.3173, -0.3096, -0.3099, -0.3147, -0.3157,\n",
      "        -0.3159, -0.3160, -0.3160, -0.3160, -0.3159, -0.3159, -0.3160, -0.3159,\n",
      "        -0.3159, -0.3159, -0.3158, -0.3157, -0.3155, -0.3153, -0.3149, -0.3144,\n",
      "        -0.3138, -0.3131, -0.3122, -0.3112, -0.3100, -0.3084, -0.3075, -0.3099,\n",
      "        -0.3123, -0.3155, -0.3221, -0.3272, -0.3264, -0.3248, -0.3236, -0.3226,\n",
      "        -0.3215, -0.3206, -0.3198, -0.3193, -0.3190, -0.3188, -0.3186, -0.3186,\n",
      "        -0.3186, -0.3187, -0.3188, -0.3188, -0.3187, -0.3188, -0.3187, -0.3188,\n",
      "        -0.3187, -0.3187, -0.3187, -0.3187, -0.3187, -0.3188, -0.3189, -0.3190,\n",
      "        -0.3190, -0.3190, -0.3191, -0.3190, -0.3188, -0.3187, -0.3186, -0.3185,\n",
      "        -0.3184, -0.3183, -0.3182, -0.3181, -0.3180, -0.3178, -0.3177, -0.3179,\n",
      "        -0.3176, -0.3172, -0.3169, -0.3165, -0.3162, -0.3159, -0.3158, -0.3157,\n",
      "        -0.3155, -0.3153, -0.3151, -0.3150, -0.3150, -0.3149, -0.3148, -0.3148,\n",
      "        -0.3143, -0.3154, -0.3190, -0.3238])\n"
     ]
    }
   ],
   "source": [
    "# Normalization of features\n",
    "mean, std = get_mean_std(loader)\n",
    "print (mean, std)\n",
    "\n",
    "dataset_normalized = ParametrizedShirtDataSet(Path(data_location), \n",
    "                                  transforms.Compose([\n",
    "                                      SampleToTensor(), \n",
    "                                      NormalizeInputfeatures(mean, std)]))\n",
    "\n",
    "print (dataset[1]['features'])\n",
    "print (dataset_normalized[1]['features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShirtfeaturesMLP(nn.Module):\n",
    "    \"\"\"MLP for training on shirts dataset. Assumes 100 features parameters used\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # layers definitions\n",
    "        self.sequence = nn.Sequential(\n",
    "            nn.Linear(36756, 3000), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(3000, 300), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(300, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(60, 9)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_batch):\n",
    "        #print (x_batch)\n",
    "        \n",
    "        return self.sequence(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShirtfeaturesMLP(\n",
      "  (sequence): Sequential(\n",
      "    (0): Linear(in_features=36756, out_features=3000, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=3000, out_features=300, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=300, out_features=60, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=60, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ShirtfeaturesMLP()\n",
    "\n",
    "print (net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Parameters\n",
    "batch_size = 64\n",
    "epochs_num = 100\n",
    "learning_rate = 0.001\n",
    "logdir = './logdir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial load\n",
    "shirt_dataset = ParametrizedShirtDataSet(Path(data_location), \n",
    "                                  SampleToTensor())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "mean, std = get_mean_std(DataLoader(shirt_dataset, 100))\n",
    "shirt_dataset = ParametrizedShirtDataSet(Path(data_location), \n",
    "                                  transforms.Compose([\n",
    "                                      SampleToTensor(), \n",
    "                                      NormalizeInputfeatures(mean, std)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 945 / 104\n"
     ]
    }
   ],
   "source": [
    "# Data load and split\n",
    "valid_size = (int) (len(shirt_dataset) / 10)\n",
    "# split is RANDOM. Might affect performance\n",
    "training_set, validation_set = torch.utils.data.random_split(\n",
    "    shirt_dataset, \n",
    "    (len(shirt_dataset) - valid_size, valid_size))\n",
    "\n",
    "print ('Split: {} / {}'.format(len(training_set), len(validation_set)))\n",
    "\n",
    "training_loader = DataLoader(training_set, batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop func\n",
    "\n",
    "def fit(model, regression_loss, optimizer, scheduler, train_loader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print (device)\n",
    "    \n",
    "    model.to(device)\n",
    "    for epoch in range (epochs_num):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(training_loader):\n",
    "            features, params = batch['features'].to(device), batch['pattern_params'].to(device)\n",
    "            \n",
    "            #with torch.autograd.detect_anomaly():\n",
    "            preds = model(features)\n",
    "            loss = regression_loss(preds, params)\n",
    "            #print ('Epoch: {}, Batch: {}, Loss: {}'.format(epoch, i, loss))\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # logging\n",
    "            if i % 5 == 4:\n",
    "                wb.log({'epoch': epoch, 'loss': loss})\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[(regression_loss(model(features), params), len(batch)) for batch in validation_loader]\n",
    "            )\n",
    "            \n",
    "        valid_loss = np.sum(losses) / np.sum(nums)\n",
    "        scheduler.step(valid_loss)\n",
    "        \n",
    "        print ('Epoch: {}, Validation Loss: {}'.format(epoch, valid_loss))\n",
    "        wb.log({'epoch': epoch, 'valid_loss': valid_loss, 'learning_rate': optimizer.param_groups[0]['lr']})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the definitions\n",
    "# model\n",
    "model = ShirtfeaturesMLP()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1)\n",
    "\n",
    "# loss function\n",
    "regression_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Catalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.distributed' has no attribute 'is_initialized'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-14dae05bc712>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mlogdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_num\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;31m#monitoring_params={\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m#    \"project\": \"Test-Garments-Reconstruction\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\dl\\runner\\supervised.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, model, criterion, optimizer, loaders, logdir, callbacks, scheduler, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, state_kwargs, checkpoint_data, fp16, monitoring_params, check)\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mmonitoring_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmonitoring_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         )\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     def infer(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\core\\runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m    376\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_exception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\core\\runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self, experiment)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\core\\runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[1;34m(self, stage)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_for_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_State\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\dl\\core\\runner.py\u001b[0m in \u001b[0;36m_prepare_for_stage\u001b[1;34m(self, stage)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prepare_for_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_for_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_global_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\core\\runner.py\u001b[0m in \u001b[0;36m_prepare_for_stage\u001b[1;34m(self, stage)\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_global_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_experiment_components\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_global_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\core\\runner.py\u001b[0m in \u001b[0;36m_get_experiment_components\u001b[1;34m(self, stage)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mscheduler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[0mdistributed_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributed_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                 \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m             )\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\utils\\distributed.py\u001b[0m in \u001b[0;36mprocess_components\u001b[1;34m(model, criterion, optimizer, scheduler, distributed_params, device)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_wrapped_with_ddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[1;31m# distributed data parallel run (ddp) (with apex support)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mget_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catalyst\\utils\\distributed.py\u001b[0m in \u001b[0;36mget_rank\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m               \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \"\"\"\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;31m#if torch.distributed.is_initialized():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;31m#    return torch.distributed.get_rank()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m#else:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.distributed' has no attribute 'is_initialized'"
     ]
    }
   ],
   "source": [
    "#from catalyst.dl import SupervisedWandbRunner\n",
    "from catalyst.dl import SupervisedRunner\n",
    "\n",
    "# data \n",
    "loaders = {\"train\": training_loader, \"valid\": validation_loader}\n",
    "\n",
    "# runner\n",
    "runner = SupervisedRunner(device=\"cpu\")\n",
    "\n",
    "# training -- at also logs a lot of stuff\n",
    "runner.train(\n",
    "    model=model,\n",
    "    criterion=regression_loss,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loaders=loaders,\n",
    "    logdir=logdir,\n",
    "    num_epochs=epochs_num,\n",
    "    verbose=True\n",
    "    #monitoring_params={\n",
    "    #    \"project\": \"Test-Garments-Reconstruction\"\n",
    "    #}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'absolute_import', 'division', 'is_available', 'print_function', 'torch', 'unicode_literals']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.distributed\n",
    "\n",
    "print (dir(torch.distributed))\n",
    "torch.cuda.device_count()\n",
    "#print(torch.distributed.is_initialized())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/maria_korosteleva/Test-Garments-Reconstruction\" target=\"_blank\">https://app.wandb.ai/maria_korosteleva/Test-Garments-Reconstruction</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/maria_korosteleva/Test-Garments-Reconstruction/runs/hvx0k475\" target=\"_blank\">https://app.wandb.ai/maria_korosteleva/Test-Garments-Reconstruction/runs/hvx0k475</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x1ba0d531668>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init Weights&biases run\n",
    "#os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "#import wandb as wb\n",
    "wb.init(name = \"mesh input LR scheduling\", project = 'Test-Garments-Reconstruction')\n",
    "\n",
    "wb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch: 0, Validation Loss: 0.0048858243972063065\n",
      "Epoch: 1, Validation Loss: 0.003998949658125639\n",
      "Epoch: 2, Validation Loss: 0.004340214654803276\n",
      "Epoch: 3, Validation Loss: 0.004565452691167593\n",
      "Epoch: 4, Validation Loss: 0.004441054537892342\n",
      "Epoch: 5, Validation Loss: 0.0040648821741342545\n",
      "Epoch: 6, Validation Loss: 0.004433665424585342\n",
      "Epoch: 7, Validation Loss: 0.004035033751279116\n",
      "Epoch: 8, Validation Loss: 0.0040302518755197525\n",
      "Epoch: 9, Validation Loss: 0.003925642929971218\n",
      "Epoch: 10, Validation Loss: 0.0038788821548223495\n",
      "Epoch: 11, Validation Loss: 0.00437322398647666\n",
      "Epoch: 12, Validation Loss: 0.004445165395736694\n",
      "Epoch: 13, Validation Loss: 0.004149965476244688\n",
      "Epoch: 14, Validation Loss: 0.004420258104801178\n",
      "Epoch: 15, Validation Loss: 0.004501714371144772\n",
      "Epoch: 16, Validation Loss: 0.003913343418389559\n",
      "Epoch: 17, Validation Loss: 0.004194024950265884\n",
      "Epoch: 18, Validation Loss: 0.0042655859142541885\n",
      "Epoch: 19, Validation Loss: 0.00472890492528677\n",
      "Epoch: 20, Validation Loss: 0.004429730121046305\n",
      "Epoch: 21, Validation Loss: 0.004165457095950842\n",
      "Epoch: 22, Validation Loss: 0.003979324363172054\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-b2b9d7365d4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregression_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Finished training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-79dc16af374f>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(model, regression_loss, optimizer, scheduler, train_loader)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pattern_params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-86690bea8361>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mdatapoint_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatapoints_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mvert_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_verts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapoint_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;31m# read the pattern parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-86690bea8361>\u001b[0m in \u001b[0;36mread_verts\u001b[1;34m(self, datapoint_name)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mmesh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_trimesh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot_path\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdatapoint_name\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgarment_3d_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmesh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "fit(model, regression_loss, optimizer, scheduler, training_loader)\n",
    "\n",
    "print (\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.02655116282403469\n"
     ]
    }
   ],
   "source": [
    "# loss on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    valid_loss = sum([regression_loss(model(batch['features']), batch['pattern_params']) for batch in validation_loader]) \n",
    "\n",
    "print ('Validation loss: {}'.format(valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions for validation to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2462974786758423, 0.7441388368606567, 0.9016931056976318, 0.6540197134017944, 1.1041333675384521, 1.2501575946807861, 1.2502353191375732, 0.8995957374572754, 0.9998902678489685]\n",
      "Saved V9SUOXEHXVLI\n",
      "[1.2463276386260986, 0.7441512942314148, 0.9017415046691895, 0.65404212474823, 1.1041481494903564, 1.2502005100250244, 1.2502684593200684, 0.8996169567108154, 0.9999186396598816]\n",
      "Saved Y6TLQDYOKMKC\n",
      "[1.2463206052780151, 0.7441489696502686, 0.901718258857727, 0.6540318727493286, 1.1041452884674072, 1.2501857280731201, 1.2502539157867432, 0.8996154069900513, 0.9999144673347473]\n",
      "Saved M6PNUHQOZYEF\n",
      "[1.246446132659912, 0.7442108392715454, 0.9018248319625854, 0.6540975570678711, 1.1042542457580566, 1.2503091096878052, 1.2503726482391357, 0.8996891975402832, 1.0000224113464355]\n",
      "Saved X5WIOMUQOEJD\n",
      "[1.2462490797042847, 0.744117021560669, 0.901656985282898, 0.6539962291717529, 1.1040825843811035, 1.250112533569336, 1.2501859664916992, 0.8995614051818848, 0.9998473525047302]\n",
      "Saved E7YOJODRKYQY\n",
      "[1.2464097738265991, 0.7441959977149963, 0.9018012285232544, 0.6540782451629639, 1.1042237281799316, 1.2502741813659668, 1.2503454685211182, 0.8996686935424805, 0.9999881386756897]\n",
      "Saved E9PPPEKYBKID\n",
      "[1.2462801933288574, 0.7441253662109375, 0.9016793966293335, 0.6540095806121826, 1.1041131019592285, 1.2501447200775146, 1.2502198219299316, 0.8995814323425293, 0.9998827576637268]\n",
      "Saved E0AHLPYSPBKE\n",
      "[1.2464090585708618, 0.7441887259483337, 0.9018077850341797, 0.6540844440460205, 1.104222059249878, 1.2502787113189697, 1.25034499168396, 0.8996715545654297, 0.9999884963035583]\n",
      "Saved D2GEWDENUQHH\n",
      "[1.2461501359939575, 0.7440717816352844, 0.901556134223938, 0.6539368629455566, 1.1039988994598389, 1.2500028610229492, 1.2500876188278198, 0.8994966745376587, 0.9997618198394775]\n",
      "Saved J5FTXFOLKGTC\n",
      "[1.2463576793670654, 0.7441674470901489, 0.9017491340637207, 0.6540508270263672, 1.1041843891143799, 1.2502214908599854, 1.2502954006195068, 0.8996360301971436, 0.9999465942382812]\n",
      "Saved I5SRVHVYJOVB\n",
      "[1.2462644577026367, 0.7441179156303406, 0.901675820350647, 0.6540015935897827, 1.1040936708450317, 1.2501299381256104, 1.2502076625823975, 0.8995711803436279, 0.999862551689148]\n",
      "Saved V9SAAHBKEYSD\n",
      "[1.246187686920166, 0.7440862655639648, 0.9015802145004272, 0.6539548635482788, 1.1040363311767578, 1.2500381469726562, 1.2501219511032104, 0.8995175361633301, 0.9997982382774353]\n",
      "Saved B4MGBVXNBZIK\n",
      "[1.2463868856430054, 0.7441824078559875, 0.901792049407959, 0.6540709733963013, 1.1042004823684692, 1.250258207321167, 1.2503244876861572, 0.8996574878692627, 0.9999670386314392]\n",
      "Saved A2UOBZJIFYZI\n",
      "[1.2463340759277344, 0.7441577315330505, 0.9017441272735596, 0.6540448665618896, 1.1041579246520996, 1.2502050399780273, 1.2502775192260742, 0.8996142148971558, 0.9999251961708069]\n",
      "Saved W5TRLFHTVENB\n",
      "[1.2463710308074951, 0.7441746592521667, 0.9017635583877563, 0.6540597677230835, 1.1041927337646484, 1.2502360343933105, 1.2503068447113037, 0.8996416330337524, 0.9999553561210632]\n",
      "Saved L9GHLWTWILNX\n",
      "[1.2464234828948975, 0.7441969513893127, 0.901816725730896, 0.6540879011154175, 1.1042349338531494, 1.2502923011779785, 1.250359296798706, 0.8996789455413818, 1.0000032186508179]\n",
      "Saved H4LKMJJZLKSV\n",
      "[1.2462432384490967, 0.7440993189811707, 0.9016519784927368, 0.6539912223815918, 1.1040737628936768, 1.2501049041748047, 1.2501825094223022, 0.8995553255081177, 0.9998475909233093]\n",
      "Saved K2QOUZMWDIWN\n",
      "[1.2460339069366455, 0.7440168857574463, 0.9014381170272827, 0.6538664102554321, 1.103906273841858, 1.2498774528503418, 1.2499797344207764, 0.8994117975234985, 0.9996687769889832]\n",
      "Saved H4VQNVEJAJOU\n",
      "[1.2463796138763428, 0.7441787123680115, 0.9017812013626099, 0.6540671586990356, 1.1041977405548096, 1.2502492666244507, 1.2503161430358887, 0.8996545076370239, 0.9999626874923706]\n",
      "Saved A0ORXEDOUCFO\n",
      "[1.2464007139205933, 0.7441884875297546, 0.9017881155014038, 0.654075026512146, 1.104217290878296, 1.2502626180648804, 1.2503330707550049, 0.8996624946594238, 0.9999802112579346]\n",
      "Saved H4IJYNLNCXJB\n",
      "[1.2464420795440674, 0.7442020177841187, 0.9018406867980957, 0.6541036367416382, 1.1042510271072388, 1.2503132820129395, 1.2503783702850342, 0.8996996879577637, 1.0000157356262207]\n",
      "Saved L6ZZJWJWPQTO\n",
      "[1.2464516162872314, 0.7442110776901245, 0.901853084564209, 0.6541053652763367, 1.104256510734558, 1.25032639503479, 1.2503899335861206, 0.8997005224227905, 1.0000262260437012]\n",
      "Saved G4JQDUHZFBCZ\n",
      "[1.2463324069976807, 0.7441550493240356, 0.9017213582992554, 0.6540376543998718, 1.1041572093963623, 1.2501921653747559, 1.2502591609954834, 0.8996150493621826, 0.9999234080314636]\n",
      "Saved B9DNRGUZQBJJ\n",
      "[1.2465293407440186, 0.744250476360321, 0.9019238948822021, 0.6541508436203003, 1.1043236255645752, 1.2504044771194458, 1.250462532043457, 0.8997530937194824, 1.0000898838043213]\n",
      "Saved C0IWNQRKACKY\n",
      "[1.2463444471359253, 0.7441593408584595, 0.9017496109008789, 0.6540466547012329, 1.1041682958602905, 1.2502156496047974, 1.2502864599227905, 0.8996244668960571, 0.9999359250068665]\n",
      "Saved T6JDVGYGPKLY\n",
      "[1.246353268623352, 0.7441666722297668, 0.9017562866210938, 0.6540505290031433, 1.104177474975586, 1.2502211332321167, 1.2502975463867188, 0.8996309041976929, 0.9999403357505798]\n",
      "Saved O4ASEXESAFOC\n",
      "[1.246260643005371, 0.7441161870956421, 0.9016715288162231, 0.6540001630783081, 1.104091763496399, 1.250129222869873, 1.2502062320709229, 0.8995680809020996, 0.9998619556427002]\n",
      "Saved W4PSDPFBBYND\n",
      "[1.246199607849121, 0.7441002130508423, 0.9016022682189941, 0.6539631485939026, 1.104040503501892, 1.2500578165054321, 1.2501351833343506, 0.8995294570922852, 0.9998087882995605]\n",
      "Saved A1KFZGQPBSLA\n",
      "[1.246427059173584, 0.7441935539245605, 0.9018280506134033, 0.6540939807891846, 1.1042381525039673, 1.250301480293274, 1.2503674030303955, 0.8996866941452026, 1.0000066757202148]\n",
      "Saved N9QULLYFQBHR\n",
      "[1.2464513778686523, 0.7442131042480469, 0.9018499851226807, 0.6541067361831665, 1.1042572259902954, 1.2503271102905273, 1.250386357307434, 0.8997021913528442, 1.0000274181365967]\n",
      "Saved B0ZLABMCXVSY\n",
      "[1.2463538646697998, 0.7441614270210266, 0.9017543792724609, 0.6540548801422119, 1.1041781902313232, 1.2502202987670898, 1.250288724899292, 0.8996398448944092, 0.9999365210533142]\n",
      "Saved K8ZSVORQUDTL\n",
      "[1.2464162111282349, 0.7441971898078918, 0.9018120765686035, 0.6540858149528503, 1.1042321920394897, 1.25028657913208, 1.2503538131713867, 0.8996741771697998, 0.9999943375587463]\n",
      "Saved D5BWALVOWDAG\n",
      "[1.2463550567626953, 0.744168758392334, 0.9017560482025146, 0.6540517807006836, 1.1041758060455322, 1.2502214908599854, 1.2502920627593994, 0.8996342420578003, 0.999940037727356]\n",
      "Saved F5QFGHIALRFW\n",
      "[1.2463825941085815, 0.7441856265068054, 0.9017752408981323, 0.6540652513504028, 1.1041998863220215, 1.2502472400665283, 1.2503143548965454, 0.8996506929397583, 0.9999645352363586]\n",
      "Saved C3KSGZMKJDKV\n",
      "[1.2463089227676392, 0.7441515922546387, 0.9017149209976196, 0.6540265083312988, 1.1041334867477417, 1.250176191329956, 1.2502467632293701, 0.8995972871780396, 0.9998988509178162]\n",
      "Saved V5SEWXFPFBFS\n",
      "[1.2465695142745972, 0.744270920753479, 0.901957631111145, 0.6541693210601807, 1.1043598651885986, 1.2504472732543945, 1.2505016326904297, 0.8997784852981567, 1.0001293420791626]\n",
      "Saved J1FTTMAZQTAK\n",
      "[1.2464804649353027, 0.7442284822463989, 0.9018748998641968, 0.6541239023208618, 1.1042859554290771, 1.250354528427124, 1.2504137754440308, 0.8997159004211426, 1.0000499486923218]\n",
      "Saved N4OVAEPKWBFN\n",
      "[1.246260643005371, 0.7441186904907227, 0.9016741514205933, 0.6540004014968872, 1.1040902137756348, 1.2501300573349, 1.2502031326293945, 0.8995697498321533, 0.9998642206192017]\n",
      "Saved C7UQLNBLIXLQ\n",
      "[1.246275544166565, 0.7441178560256958, 0.9016828536987305, 0.6540123820304871, 1.104107141494751, 1.2501401901245117, 1.250216007232666, 0.899579644203186, 0.9998746514320374]\n",
      "Saved A2ODYFNZIRBM\n",
      "[1.2463221549987793, 0.7441585659980774, 0.9017237424850464, 0.6540340185165405, 1.104148507118225, 1.2501871585845947, 1.250258207321167, 0.8996082544326782, 0.9999116659164429]\n",
      "Saved I9OHPEDNKSYS\n",
      "[1.2463579177856445, 0.7441549897193909, 0.9017566442489624, 0.6540542840957642, 1.104180097579956, 1.2502254247665405, 1.2502992153167725, 0.8996376991271973, 0.9999479651451111]\n",
      "Saved H0DAHNXQTIKV\n",
      "[1.2463369369506836, 0.7441554069519043, 0.9017369747161865, 0.6540431976318359, 1.1041572093963623, 1.250196933746338, 1.2502681016921997, 0.899626612663269, 0.9999206066131592]\n",
      "Saved Y7QMGGINLGGC\n",
      "[1.2464046478271484, 0.7441933155059814, 0.9018003940582275, 0.6540780067443848, 1.1042182445526123, 1.250271201133728, 1.2503385543823242, 0.8996680974960327, 0.9999813437461853]\n",
      "Saved G7DLDOOTHQNV\n",
      "[1.2463858127593994, 0.7441849112510681, 0.9017952680587769, 0.6540721654891968, 1.1041995286941528, 1.2502593994140625, 1.2503256797790527, 0.8996551036834717, 0.9999670386314392]\n",
      "Saved U0JPHWOTCKTF\n",
      "[1.246516466140747, 0.7442446947097778, 0.9019030332565308, 0.6541383266448975, 1.1043150424957275, 1.2503902912139893, 1.2504496574401855, 0.8997437953948975, 1.0000848770141602]\n",
      "Saved B6VDHQRVDUZK\n",
      "[1.2464241981506348, 0.7442011833190918, 0.9018139839172363, 0.6540881395339966, 1.1042362451553345, 1.2502893209457397, 1.25035560131073, 0.8996783494949341, 1.0000009536743164]\n",
      "Saved P1YABTHUBXLI\n",
      "[1.246381402015686, 0.7441819906234741, 0.9017833471298218, 0.6540670394897461, 1.1041984558105469, 1.2502493858337402, 1.2503201961517334, 0.8996517658233643, 0.9999629259109497]\n",
      "Saved P8BLXXVFSUEB\n",
      "[1.2464873790740967, 0.7442256212234497, 0.9018880128860474, 0.6541252136230469, 1.1042896509170532, 1.250368356704712, 1.2504299879074097, 0.8997231721878052, 1.0000624656677246]\n",
      "Saved X6IQJRQQRJWS\n",
      "[1.246260643005371, 0.7441246509552002, 0.9016567468643188, 0.653998851776123, 1.1040966510772705, 1.2501170635223389, 1.250194787979126, 0.8995673656463623, 0.99985671043396]\n",
      "Saved N2LQTZGOVDDP\n",
      "[1.246361494064331, 0.7441731691360474, 0.9017444849014282, 0.6540499925613403, 1.104177713394165, 1.2502179145812988, 1.2502856254577637, 0.8996337652206421, 0.999944806098938]\n",
      "Saved Z7DPNMVQSYIY\n",
      "[1.246422290802002, 0.7441942095756531, 0.9018405675888062, 0.6540892720222473, 1.1042317152023315, 1.2503042221069336, 1.250377893447876, 0.8996762037277222, 1.000007152557373]\n",
      "Saved N9DPWNNQMFQS\n",
      "[1.2463679313659668, 0.7441725134849548, 0.9017788171768188, 0.6540637016296387, 1.1041866540908813, 1.2502405643463135, 1.2503104209899902, 0.8996390104293823, 0.9999527931213379]\n",
      "Saved N3MOMNYBSSYD\n",
      "[1.2464196681976318, 0.7441986799240112, 0.9018102884292603, 0.6540880799293518, 1.1042330265045166, 1.2502851486206055, 1.250352382659912, 0.8996745347976685, 0.9999943971633911]\n",
      "Saved O2OGNOYRKTWS\n",
      "[1.2465155124664307, 0.7442449927330017, 0.901907205581665, 0.6541401147842407, 1.1043156385421753, 1.2503927946090698, 1.250450849533081, 0.8997421264648438, 1.000083327293396]\n",
      "Saved S1PHEJYCZMYB\n",
      "[1.2465040683746338, 0.7442333698272705, 0.9019128084182739, 0.6541405916213989, 1.104301929473877, 1.2503857612609863, 1.2504465579986572, 0.8997364044189453, 1.000070571899414]\n",
      "Saved M3JDZYFXHRMZ\n",
      "[1.2463295459747314, 0.7441583871841431, 0.9017249345779419, 0.654036283493042, 1.104154348373413, 1.2501895427703857, 1.2502624988555908, 0.8996162414550781, 0.9999157190322876]\n",
      "Saved S0DHSXOWJOEY\n",
      "[1.2463080883026123, 0.7441398501396179, 0.9017176628112793, 0.6540290117263794, 1.104134440422058, 1.2501771450042725, 1.2502509355545044, 0.8996015787124634, 0.9999043941497803]\n",
      "Saved L1EJTOZTZKKQ\n",
      "[1.2462100982666016, 0.7440946102142334, 0.9016152620315552, 0.6539736986160278, 1.1040525436401367, 1.2500677108764648, 1.250147819519043, 0.8995331525802612, 0.9998158812522888]\n",
      "Saved C6LPFAORSVOF\n",
      "[1.2462937831878662, 0.744132936000824, 0.9016826152801514, 0.6540138721466064, 1.1041243076324463, 1.2501509189605713, 1.2502284049987793, 0.8995895385742188, 0.9998916983604431]\n",
      "Saved D4XVRSPGQHKC\n",
      "[1.2462396621704102, 0.74411541223526, 0.9016293287277222, 0.6539794206619263, 1.104081392288208, 1.250091552734375, 1.2501753568649292, 0.8995494842529297, 0.9998432993888855]\n",
      "Saved L1WQEFFTHSPQ\n",
      "[1.246402382850647, 0.7441871166229248, 0.9018046855926514, 0.654080867767334, 1.104215145111084, 1.2502686977386475, 1.2503392696380615, 0.8996678590774536, 0.9999754428863525]\n",
      "Saved W0QDPWNZKUHD\n",
      "[1.2464404106140137, 0.7442125082015991, 0.9018380641937256, 0.6541042327880859, 1.1042630672454834, 1.2503271102905273, 1.250385046005249, 0.8997001647949219, 1.0000312328338623]\n",
      "Saved M8HCNOCCKLXA\n",
      "[1.2463860511779785, 0.7441823482513428, 0.9017891883850098, 0.6540703773498535, 1.1042038202285767, 1.2502577304840088, 1.2503247261047363, 0.8996541500091553, 0.9999699592590332]\n",
      "Saved A3BYKOUWHLMC\n",
      "[1.2464386224746704, 0.744208037853241, 0.9018220901489258, 0.6540950536727905, 1.1042503118515015, 1.2503042221069336, 1.2503689527511597, 0.8996886014938354, 1.0000154972076416]\n",
      "Saved D1BZXWAWXNHF\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(validation_loader))    # might have some issues, see https://github.com/pytorch/pytorch/issues/1917\n",
    "    shirt_dataset_normalized.save_prediction_batch(model(batch['features']), batch['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
